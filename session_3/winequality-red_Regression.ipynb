{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842d2731",
   "metadata": {},
   "source": [
    "#### 3회차 Assignment\n",
    "winequality-red 데이터에서 residual sugar를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b829ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529fbf9",
   "metadata": {},
   "source": [
    "분류 문제를 해결할 때 winequality-red.csv 파일이 쉼표가 아닌 세미콜론으로 클래스들이 구분되어 있으므로 명령어를 통해 세미콜론을 쉽표로 바꿔준 파일 redwine.csv를 활용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4541dcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7.4</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.8</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.8</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.2</th>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.4</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.2</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.9</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.3</th>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.9</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "fixed acidity                                                             \n",
       "7.4                       0.700         0.00             1.9      0.076   \n",
       "7.8                       0.880         0.00             2.6      0.098   \n",
       "7.8                       0.760         0.04             2.3      0.092   \n",
       "11.2                      0.280         0.56             1.9      0.075   \n",
       "7.4                       0.700         0.00             1.9      0.076   \n",
       "...                         ...          ...             ...        ...   \n",
       "6.2                       0.600         0.08             2.0      0.090   \n",
       "5.9                       0.550         0.10             2.2      0.062   \n",
       "6.3                       0.510         0.13             2.3      0.076   \n",
       "5.9                       0.645         0.12             2.0      0.075   \n",
       "6.0                       0.310         0.47             3.6      0.067   \n",
       "\n",
       "               free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "fixed acidity                                                             \n",
       "7.4                           11.0                  34.0  0.99780  3.51   \n",
       "7.8                           25.0                  67.0  0.99680  3.20   \n",
       "7.8                           15.0                  54.0  0.99700  3.26   \n",
       "11.2                          17.0                  60.0  0.99800  3.16   \n",
       "7.4                           11.0                  34.0  0.99780  3.51   \n",
       "...                            ...                   ...      ...   ...   \n",
       "6.2                           32.0                  44.0  0.99490  3.45   \n",
       "5.9                           39.0                  51.0  0.99512  3.52   \n",
       "6.3                           29.0                  40.0  0.99574  3.42   \n",
       "5.9                           32.0                  44.0  0.99547  3.57   \n",
       "6.0                           18.0                  42.0  0.99549  3.39   \n",
       "\n",
       "               sulphates  alcohol  quality  \n",
       "fixed acidity                               \n",
       "7.4                 0.56      9.4        5  \n",
       "7.8                 0.68      9.8        5  \n",
       "7.8                 0.65      9.8        5  \n",
       "11.2                0.58      9.8        6  \n",
       "7.4                 0.56      9.4        5  \n",
       "...                  ...      ...      ...  \n",
       "6.2                 0.58     10.5        5  \n",
       "5.9                 0.76     11.2        6  \n",
       "6.3                 0.75     11.0        6  \n",
       "5.9                 0.71     10.2        5  \n",
       "6.0                 0.66     11.0        6  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('C:/Users/yoojm/AIStudy/practice/Dataset/redwine.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a045098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity\n",
       "7.4     1.9\n",
       "7.8     2.6\n",
       "7.8     2.3\n",
       "11.2    1.9\n",
       "7.4     1.9\n",
       "       ... \n",
       "6.2     2.0\n",
       "5.9     2.2\n",
       "6.3     2.3\n",
       "5.9     2.0\n",
       "6.0     3.6\n",
       "Name: residual sugar, Length: 1599, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['residual sugar']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636133fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7.4</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.8</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.8</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.2</th>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.4</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.2</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.9</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.3</th>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.9</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               volatile acidity  citric acid  chlorides  free sulfur dioxide  \\\n",
       "fixed acidity                                                                  \n",
       "7.4                       0.700         0.00      0.076                 11.0   \n",
       "7.8                       0.880         0.00      0.098                 25.0   \n",
       "7.8                       0.760         0.04      0.092                 15.0   \n",
       "11.2                      0.280         0.56      0.075                 17.0   \n",
       "7.4                       0.700         0.00      0.076                 11.0   \n",
       "...                         ...          ...        ...                  ...   \n",
       "6.2                       0.600         0.08      0.090                 32.0   \n",
       "5.9                       0.550         0.10      0.062                 39.0   \n",
       "6.3                       0.510         0.13      0.076                 29.0   \n",
       "5.9                       0.645         0.12      0.075                 32.0   \n",
       "6.0                       0.310         0.47      0.067                 18.0   \n",
       "\n",
       "               total sulfur dioxide  density    pH  sulphates  alcohol  \\\n",
       "fixed acidity                                                            \n",
       "7.4                            34.0  0.99780  3.51       0.56      9.4   \n",
       "7.8                            67.0  0.99680  3.20       0.68      9.8   \n",
       "7.8                            54.0  0.99700  3.26       0.65      9.8   \n",
       "11.2                           60.0  0.99800  3.16       0.58      9.8   \n",
       "7.4                            34.0  0.99780  3.51       0.56      9.4   \n",
       "...                             ...      ...   ...        ...      ...   \n",
       "6.2                            44.0  0.99490  3.45       0.58     10.5   \n",
       "5.9                            51.0  0.99512  3.52       0.76     11.2   \n",
       "6.3                            40.0  0.99574  3.42       0.75     11.0   \n",
       "5.9                            44.0  0.99547  3.57       0.71     10.2   \n",
       "6.0                            42.0  0.99549  3.39       0.66     11.0   \n",
       "\n",
       "               quality  \n",
       "fixed acidity           \n",
       "7.4                  5  \n",
       "7.8                  5  \n",
       "7.8                  5  \n",
       "11.2                 6  \n",
       "7.4                  5  \n",
       "...                ...  \n",
       "6.2                  5  \n",
       "5.9                  6  \n",
       "6.3                  6  \n",
       "5.9                  5  \n",
       "6.0                  6  \n",
       "\n",
       "[1599 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop('residual sugar', axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3958ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1199, 10), (400, 10), (1199,), (400,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train & test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c8080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37eb3d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04083951024142407\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "clf_svm = SVR()\n",
    "clf_svm.fit(x_train, y_train)\n",
    "\n",
    "pred_svm = clf_svm.predict(x_test)\n",
    "\n",
    "print(clf_svm.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4711190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균제곱근오차 1.197416855083247\n"
     ]
    }
   ],
   "source": [
    "mse = np.sqrt(mean_squared_error(pred_svm, y_test))\n",
    "print('평균제곱근오차', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a082d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29637481070399097\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "clf_lr = LinearRegression()\n",
    "clf_lr.fit(x_train, y_train)\n",
    "\n",
    "pred_lr = clf_lr.predict(x_test)\n",
    "\n",
    "print(clf_lr.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c27b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균제곱근오차 1.0714712747390223\n"
     ]
    }
   ],
   "source": [
    "mse = np.sqrt(mean_squared_error(pred_lr, y_test))\n",
    "print('평균제곱근오차', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90fa14d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "clf_dt = DecisionTreeRegressor()\n",
    "clf_dt.fit(x_train, y_train)\n",
    "\n",
    "pred_dt = clf_dt.predict(x_test)\n",
    "\n",
    "print(clf_dt.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2124a92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균제곱근오차 1.0774912992688155\n"
     ]
    }
   ],
   "source": [
    "mse = np.sqrt(mean_squared_error(pred_dt, y_test))\n",
    "print('평균제곱근오차', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d8967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942563719762355\n"
     ]
    }
   ],
   "source": [
    "# RF\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_clf = RandomForestRegressor()\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "pred_rf = rf_clf.predict(x_test)\n",
    "\n",
    "print(rf_clf.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f3d748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균제곱근오차 0.912466481918651\n"
     ]
    }
   ],
   "source": [
    "mse = np.sqrt(mean_squared_error(pred_rf, y_test))\n",
    "print('평균제곱근오차', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8282ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07731497817558719\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "k_range = range(1, 113)\n",
    "find_accuracy = []\n",
    "\n",
    "for k in k_range:\n",
    "  KNR = KNeighborsRegressor(n_neighbors = k)\n",
    "  KNR.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "  find_accuracy.append(KNR.score(x_test, y_test))\n",
    "  \n",
    "pred_KNR = KNR.predict(x_test)\n",
    "print(KNR.score(x_train, y_train))\n",
    "\n",
    "plt.plot(k_range, find_accuracy, label=\"training accuracy\")\n",
    "plt.xlabel(\"k value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dca6b726",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균제곱근오차 1.152704826256059\n"
     ]
    }
   ],
   "source": [
    "mse = np.sqrt(mean_squared_error(pred_KNR, y_test))\n",
    "print('평균제곱근오차', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ccd595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling: 0\n",
      "Missing values after handling: 0\n",
      "\n",
      "Classification Task:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "keywords must be strings",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Task:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m classification_models:\n\u001b[1;32m---> 82\u001b[0m     \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Train and evaluate regression models\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRegression Task:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 50\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(model, X_train, X_test, y_train, y_test, task)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scaler \u001b[38;5;129;01min\u001b[39;00m scalers:\n\u001b[0;32m     49\u001b[0m     model_pipe\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m (scaler, model)\n\u001b[1;32m---> 50\u001b[0m     \u001b[43mmodel_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     53\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m model_pipe\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    415\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 416\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: keywords must be strings"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load the Wine Quality dataset from the UCI Machine Learning Repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Classify 'quality' (classification problem)\n",
    "X_classification = wine_data.drop('quality', axis=1)\n",
    "y_classification = wine_data['quality']\n",
    "\n",
    "# Regression for 'residual sugar' (regression problem)\n",
    "X_regression = wine_data.drop('residual sugar', axis=1)\n",
    "y_regression = wine_data['residual sugar']\n",
    "\n",
    "# Split the data for classification\n",
    "X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(\n",
    "    X_classification, y_classification, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# Split the data for regression\n",
    "X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(\n",
    "    X_regression, y_regression, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# Check and handle missing values\n",
    "print(\"Missing values before handling:\", wine_data.isnull().sum().sum())\n",
    "wine_data = wine_data.dropna()  # Remove rows with missing values\n",
    "print(\"Missing values after handling:\", wine_data.isnull().sum().sum())\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, task):\n",
    "    # PolynomialFeatures\n",
    "    degree = 2\n",
    "    model_pipe = make_pipeline(PolynomialFeatures(degree), model)\n",
    "\n",
    "    # Scalers\n",
    "    scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "    \n",
    "    for scaler in scalers:\n",
    "        model_pipe.steps[1] = (scaler, model)\n",
    "        model_pipe.fit(X_train, y_train)\n",
    "\n",
    "        if task == \"classification\":\n",
    "            y_pred = model_pipe.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"{model.__class__.__name__} with {scaler.__class__.__name__}: Accuracy = {accuracy:.4f}\")\n",
    "        elif task == \"regression\":\n",
    "            y_pred = model_pipe.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print(f\"{model.__class__.__name__} with {scaler.__class__.__name__}: MSE = {mse:.4f}\")\n",
    "\n",
    "# Models for classification\n",
    "classification_models = [\n",
    "    SVC(random_state=0),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    KNeighborsClassifier(),\n",
    "]\n",
    "\n",
    "# Models for regression\n",
    "regression_models = [\n",
    "    SVR(),\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(random_state=0),\n",
    "    RandomForestRegressor(random_state=0),\n",
    "    KNeighborsRegressor(),\n",
    "]\n",
    "\n",
    "# Train and evaluate classification models\n",
    "print(\"\\nClassification Task:\")\n",
    "for model in classification_models:\n",
    "    train_and_evaluate_model(model, X_train_classification, X_test_classification, y_train_classification, y_test_classification, \"classification\")\n",
    "\n",
    "# Train and evaluate regression models\n",
    "print(\"\\nRegression Task:\")\n",
    "for model in regression_models:\n",
    "    train_and_evaluate_model(model, X_train_regression, X_test_regression, y_train_regression, y_test_regression, \"regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74230b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling: 0\n",
      "Missing values after handling: 0\n",
      "\n",
      "Classification Task:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "keywords must be strings",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Task:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m classification_models:\n\u001b[1;32m---> 82\u001b[0m     \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Train and evaluate regression models\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRegression Task:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 50\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(model, X_train, X_test, y_train, y_test, task)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scaler \u001b[38;5;129;01min\u001b[39;00m scalers:\n\u001b[0;32m     49\u001b[0m     model_pipe\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m (scaler, model)\n\u001b[1;32m---> 50\u001b[0m     \u001b[43mmodel_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     53\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m model_pipe\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    415\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 416\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: keywords must be strings"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load the Wine Quality dataset from the UCI Machine Learning Repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Classify 'quality' (classification problem)\n",
    "X_classification = wine_data.drop('quality', axis=1)\n",
    "y_classification = wine_data['quality']\n",
    "\n",
    "# Regression for 'residual sugar' (regression problem)\n",
    "X_regression = wine_data.drop('residual sugar', axis=1)\n",
    "y_regression = wine_data['residual sugar']\n",
    "\n",
    "# Split the data for classification\n",
    "X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(\n",
    "    X_classification, y_classification, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# Split the data for regression\n",
    "X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(\n",
    "    X_regression, y_regression, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# Check and handle missing values\n",
    "print(\"Missing values before handling:\", wine_data.isnull().sum().sum())\n",
    "wine_data = wine_data.dropna()  # Remove rows with missing values\n",
    "print(\"Missing values after handling:\", wine_data.isnull().sum().sum())\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, task):\n",
    "    # PolynomialFeatures\n",
    "    degree = 2\n",
    "    model_pipe = make_pipeline(PolynomialFeatures(degree=degree), model)\n",
    "\n",
    "    # Scalers\n",
    "    scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "    \n",
    "    for scaler in scalers:\n",
    "        model_pipe.steps[1] = (scaler, model)\n",
    "        model_pipe.fit(X_train, y_train)\n",
    "\n",
    "        if task == \"classification\":\n",
    "            y_pred = model_pipe.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"{model.__class__.__name__} with {scaler.__class__.__name__}: Accuracy = {accuracy:.4f}\")\n",
    "        elif task == \"regression\":\n",
    "            y_pred = model_pipe.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print(f\"{model.__class__.__name__} with {scaler.__class__.__name__}: MSE = {mse:.4f}\")\n",
    "\n",
    "# Models for classification\n",
    "classification_models = [\n",
    "    SVC(random_state=0),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    KNeighborsClassifier(),\n",
    "]\n",
    "\n",
    "# Models for regression\n",
    "regression_models = [\n",
    "    SVR(),\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(random_state=0),\n",
    "    RandomForestRegressor(random_state=0),\n",
    "    KNeighborsRegressor(),\n",
    "]\n",
    "\n",
    "# Train and evaluate classification models\n",
    "print(\"\\nClassification Task:\")\n",
    "for model in classification_models:\n",
    "    train_and_evaluate_model(model, X_train_classification, X_test_classification, y_train_classification, y_test_classification, \"classification\")\n",
    "\n",
    "# Train and evaluate regression models\n",
    "print(\"\\nRegression Task:\")\n",
    "for model in regression_models:\n",
    "    train_and_evaluate_model(model, X_train_regression, X_test_regression, y_train_regression, y_test_regression, \"regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfec8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
